{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b74c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# IMPORTS\n",
    "# =================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519932ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# CONFIGURATION & INITIALIZATION\n",
    "# =================================================================\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Verify API key is loaded\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "\n",
    "# Model configuration\n",
    "MODEL = \"gpt-4.1-mini\"\n",
    "openai = OpenAI()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c6c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# SYSTEM PROMPT & TOOL DEFINITION\n",
    "# =================================================================\n",
    "\n",
    "systemPrompt = '''You are a wise Buddhist monk. When a user shares how they are feeling, provide:\n",
    "\n",
    "1. A comforting Buddhist quote (wrapped in <QUOTE></QUOTE> tags)\n",
    "2. Additional wisdom on how to interpret the quote\n",
    "\n",
    "Format your response like this:\n",
    "<QUOTE>The quote text here</QUOTE>\n",
    "Additional commentary and wisdom here...\n",
    "\n",
    "Do not include the author name if it is just \"Buddha\" or \"Unknown\", unless it is a specific other teacher. \n",
    "\n",
    "If the feeling is not shared (e.g., someone says hello), simply say hello back and ask how they are feeling. No need for quote tags in that case.\n",
    "\n",
    "When the user shares a genuine feeling or emotional state (like sad, happy, anxious, peaceful, etc.), you should call the generate_spiritual_image tool to create a comforting visual representation.'''\n",
    "\n",
    "# Tool definition for image generation\n",
    "image_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"generate_spiritual_image\",\n",
    "        \"description\": \"Generate a serene, spiritual Buddhist-style image to comfort the user based on their emotional state. Only call this when the user has shared a genuine feeling or emotion (e.g., sad, anxious, peaceful, grateful). Do NOT call this for greetings like 'hello' or general questions.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"feeling\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The user's emotional state or feeling to visualize (e.g., 'sadness', 'anxiety', 'peace', 'gratitude')\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"feeling\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = [image_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079122bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# MAIN CHAT FUNCTION (With Tool Calling)\n",
    "# =================================================================\n",
    "\n",
    "def extract_quote(text):\n",
    "    \"\"\"\n",
    "    Extract text between <QUOTE></QUOTE> tags.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Full message with quote tags\n",
    "    \n",
    "    Returns:\n",
    "        str: Just the quote text, or full text if no tags found\n",
    "    \"\"\"\n",
    "    import re\n",
    "    match = re.search(r'<QUOTE>(.*?)</QUOTE>', text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return text  # Return full text if no quote tags\n",
    "\n",
    "\n",
    "def remove_quote_tags(text):\n",
    "    \"\"\"\n",
    "    Remove <QUOTE></QUOTE> tags from text for clean display.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text with quote tags\n",
    "    \n",
    "    Returns:\n",
    "        str: Text with tags removed\n",
    "    \"\"\"\n",
    "    import re\n",
    "    return re.sub(r'<QUOTE>|</QUOTE>', '', text)\n",
    "\n",
    "\n",
    "def chat(history):\n",
    "    \"\"\"\n",
    "    Main chat callback that handles conversation with the Buddhist monk AI.\n",
    "    Now includes tool calling for conditional image generation.\n",
    "    \n",
    "    Args:\n",
    "        history (list): List of message dictionaries with 'role' and 'content' keys\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (updated_history, audio_bytes, image_object)\n",
    "    \"\"\"\n",
    "    global current_image\n",
    "    current_image = None  # Reset image for each message\n",
    "    \n",
    "    # Handle empty history edge case\n",
    "    if not history or len(history) == 0:\n",
    "        return history, None, None\n",
    "    \n",
    "    # Extract the user's latest message (added by put_message_in_chatbot)\n",
    "    message = history[-1][\"content\"]\n",
    "    \n",
    "    # Prepare conversation history for API (exclude last message as we'll add it explicitly)\n",
    "    history_for_api = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history[:-1]]\n",
    "    messages = [{\"role\": \"system\", \"content\": systemPrompt}] + history_for_api + [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    # First API call with tools available\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL, \n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )\n",
    "    \n",
    "    # Check if LLM wants to call the image generation tool\n",
    "    while response.choices[0].finish_reason == \"tool_calls\":\n",
    "        assistant_message = response.choices[0].message\n",
    "        \n",
    "        # Execute the tool(s)\n",
    "        for tool_call in assistant_message.tool_calls:\n",
    "            if tool_call.function.name == \"generate_spiritual_image\":\n",
    "                arguments = json.loads(tool_call.function.arguments)\n",
    "                feeling = arguments.get(\"feeling\")\n",
    "                result = generate_spiritual_image(feeling)\n",
    "                \n",
    "                # Add tool response to messages\n",
    "                messages.append(assistant_message)\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"content\": result,\n",
    "                    \"tool_call_id\": tool_call.id\n",
    "                })\n",
    "        \n",
    "        # Call API again with tool results\n",
    "        response = openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            tools=tools\n",
    "        )\n",
    "    \n",
    "    # Get final assistant message\n",
    "    assistant_message = response.choices[0].message.content\n",
    "    \n",
    "    # Extract just the quote for audio (or full message if no quote)\n",
    "    quote_only = extract_quote(assistant_message)\n",
    "    audio = talker(quote_only)\n",
    "    \n",
    "    # Remove quote tags for clean display in chat\n",
    "    display_message = remove_quote_tags(assistant_message)\n",
    "    \n",
    "    # Add cleaned message to history\n",
    "    history.append({\"role\": \"assistant\", \"content\": display_message})\n",
    "    \n",
    "    # Return the image if it was generated, otherwise None\n",
    "    return history, audio, current_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebdbb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# HELPER FUNCTIONS - OpenAI API Calls\n",
    "# =================================================================\n",
    "\n",
    "def generate_spiritual_image(feeling):\n",
    "    \"\"\"\n",
    "    TOOL FUNCTION: Generate a Buddhist-style image using DALL-E 3.\n",
    "    This is called by the LLM when the user shares a genuine feeling.\n",
    "    \n",
    "    Args:\n",
    "        feeling (str): The user's emotional state or message\n",
    "    \n",
    "    Returns:\n",
    "        str: Confirmation message (image is returned separately)\n",
    "    \"\"\"\n",
    "    print(f\"ðŸŽ¨ TOOL CALLED: Generating spiritual image for feeling: {feeling}\")\n",
    "    image_response = openai.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=f\"A serene, spiritual, abstract Buddhist style painting representing the feeling of {feeling}\",\n",
    "        size=\"1024x1024\",\n",
    "        n=1,\n",
    "        response_format=\"b64_json\",\n",
    "    )\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    # Store the image globally so we can access it after tool call\n",
    "    global current_image\n",
    "    current_image = Image.open(BytesIO(image_data))\n",
    "    return f\"Spiritual image generated for {feeling}\"\n",
    "\n",
    "\n",
    "def talker(message):\n",
    "    \"\"\"\n",
    "    Convert text to speech using OpenAI's TTS model.\n",
    "    \n",
    "    Args:\n",
    "        message (str): The text to convert to speech\n",
    "    \n",
    "    Returns:\n",
    "        bytes: Audio content in the response\n",
    "    \"\"\"\n",
    "    response = openai.audio.speech.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=\"onyx\",  # Try: alloy, echo, fable, onyx, nova, shimmer\n",
    "        input=message\n",
    "    )\n",
    "    return response.content\n",
    "\n",
    "\n",
    "# Global variable to store current image\n",
    "current_image = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a58de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# GRADIO UI SETUP\n",
    "# =================================================================\n",
    "\n",
    "def put_message_in_chatbot(message, history):\n",
    "    \"\"\"\n",
    "    Callback to add user's message to the chatbot history.\n",
    "    This is called BEFORE the chat() function.\n",
    "    \n",
    "    Args:\n",
    "        message (str): User's input text\n",
    "        history (list): Current conversation history\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (empty_string, updated_history) - clears input box and adds user message\n",
    "    \"\"\"\n",
    "    return \"\", history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "\n",
    "# Define the Gradio interface using Blocks for custom layout\n",
    "with gr.Blocks() as ui:\n",
    "    # Top row: Chatbot on left, image output on right\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "        image_output = gr.Image(height=500, interactive=False)\n",
    "    \n",
    "    # Middle row: Audio output (plays automatically)\n",
    "    with gr.Row():\n",
    "        audio_output = gr.Audio(autoplay=True)\n",
    "    \n",
    "    # Bottom row: Text input for user messages\n",
    "    with gr.Row():\n",
    "        message = gr.Textbox(label=\"Share how you're feeling:\")\n",
    "\n",
    "    # Event chain: \n",
    "    # 1. User submits message -> put_message_in_chatbot adds it to history\n",
    "    # 2. Then chat() processes it and returns updated history, audio, and image\n",
    "    message.submit(\n",
    "        put_message_in_chatbot, \n",
    "        inputs=[message, chatbot], \n",
    "        outputs=[message, chatbot]\n",
    "    ).then(\n",
    "        chat, \n",
    "        inputs=chatbot, \n",
    "        outputs=[chatbot, audio_output, image_output]\n",
    "    )\n",
    "\n",
    "# Launch the interface\n",
    "# inbrowser=True: Opens in default browser\n",
    "# inline=False: Prevents inline display in notebook\n",
    "ui.launch(inbrowser=True, inline=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bf1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# NOTES & OPTIMIZATION SUMMARY\n",
    "# =================================================================\n",
    "\n",
    "\"\"\"\n",
    "âœ… CODE STRUCTURE (Optimal Order):\n",
    "1. Imports - All dependencies grouped together\n",
    "2. Configuration - API keys, models, database settings\n",
    "3. System Prompt & Tool Definition - AI behavior + image generation tool\n",
    "4. Helper Functions - generate_spiritual_image() and talker()\n",
    "5. Main Chat Function - Core conversation logic with tool calling\n",
    "6. Gradio UI - Interface definition and launch\n",
    "\n",
    "âœ… KEY FEATURES:\n",
    "- Multi-modal Buddhist monk chatbot\n",
    "- Text responses with quote + commentary (displayed in chat)\n",
    "- Text-to-speech audio (ONLY the quote, not commentary)\n",
    "- **SMART** DALL-E image generation (only when user shares a feeling!)\n",
    "- Conversation history maintained throughout session\n",
    "\n",
    "âœ… AUDIO OPTIMIZATION:\n",
    "- System prompt instructs LLM to wrap quotes in <QUOTE></QUOTE> tags\n",
    "- extract_quote() function extracts just the quote from response\n",
    "- Audio only speaks the pure quote, not the commentary\n",
    "- User sees full message in chat, hears only the quote\n",
    "- Creates a more meditative, focused audio experience\n",
    "\n",
    "âœ… TOOL CALLING IMPLEMENTATION:\n",
    "- Image generation is a TOOL that the LLM decides to call\n",
    "- LLM only calls the tool when user shares genuine emotion (sad, anxious, etc.)\n",
    "- Greetings like \"hello\" won't trigger expensive image generation\n",
    "- Saves cost by generating images only when contextually appropriate\n",
    "\n",
    "âœ… HOW IT WORKS:\n",
    "1. User sends message\n",
    "2. LLM analyzes if it's a feeling/emotion\n",
    "3. If YES â†’ calls generate_spiritual_image tool â†’ image appears\n",
    "4. If NO (greeting/question) â†’ responds without calling tool â†’ no image\n",
    "5. Audio extracts and speaks ONLY the quote portion\n",
    "\n",
    "âœ… OPTIMIZATION NOTES:\n",
    "- Tool-based approach reduces unnecessary API costs\n",
    "- Global variable stores generated image temporarily\n",
    "- Regex extraction cleanly separates quote from commentary\n",
    "- Proper tool calling loop handles multiple tool calls\n",
    "- Type=\"messages\" ensures correct Gradio format\n",
    "\n",
    "âœ… COST SAVINGS:\n",
    "- DALL-E 3 images: $0.04-$0.12 per image (only when needed)\n",
    "- Expected image cost reduction: 50-70%\n",
    "- TTS audio runs for all responses but only on quote text (shorter = cheaper)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f4aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
